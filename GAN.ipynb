{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Orw9qFybFolS"
      },
      "source": [
        "## **First, Create the folder **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqRrS64cGIzC"
      },
      "source": [
        "import os\n",
        "os.mkdir(\"result\")\n",
        "os.mkdir(\"para\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW0u0rFCOHEU"
      },
      "source": [
        "## **Second, Download the trainingset from Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0uSOg6QMMcO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7dbccad7-8915-4007-9e30-a8074729ad72"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        " \n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        " \n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1ROGET9rA5WAdU3C8Lfs5mxg5ufLD2uCO'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "# print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
        "\n",
        "\n",
        "print('title: %s, mimeType: %s' % (downloaded['title'], downloaded['mimeType']))\n",
        "downloaded.GetContentFile(downloaded['title'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 17.6MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 3.2MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 2.6MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 3.2MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 4.1MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 4.6MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 3.5MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 3.6MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 5.0MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 5.0MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 9.4MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 9.4MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 9.4MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 9.2MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 9.3MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 9.3MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 41.8MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 10.7MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 10.7MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 10.7MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 10.6MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 10.6MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 10.4MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 10.6MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 10.6MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 10.6MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 10.7MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 43.5MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 43.9MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 46.4MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 43.2MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 43.4MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 47.8MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 46.5MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 47.0MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 12.7MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 12.7MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 12.6MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 12.5MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 12.5MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 12.6MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 12.6MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 12.7MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 12.7MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 12.7MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 47.4MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 45.2MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 46.5MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 48.1MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 48.2MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 51.8MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 51.6MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 50.1MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 49.5MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 49.1MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 49.7MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 53.6MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 53.2MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 52.1MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 50.5MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 49.5MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 40.7MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 16.1MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 16.0MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 16.0MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 15.9MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 15.9MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 16.0MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 16.0MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 16.1MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 16.2MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 17.4MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 50.5MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 50.4MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 51.0MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 52.7MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 52.0MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 52.2MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 52.3MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 51.7MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 45.9MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 46.2MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 47.6MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 49.2MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 49.0MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 48.8MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 48.7MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 48.0MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 47.8MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 47.9MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 53.7MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 53.7MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 53.4MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 20.5MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25htitle: facedata.mat, mimeType: application/octet-stream\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXVlbgp4OSjV"
      },
      "source": [
        "## **Third, Execute the GAN lib here, have fun~~**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE4xqi3jCs0w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "916fda85-a170-4799-e19a-30c9d8ce338e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "img_H = 64\n",
        "img_W = 64\n",
        "img_C = 3\n",
        "GAN_type = \"SNGAN\"  # DCGAN, WGAN, WGAN-GP, SNGAN, LSGAN, RSGAN, RaSGAN\n",
        "batchsize = 128\n",
        "epsilon = 1e-14#if epsilon is too big, training of DCGAN is failure.\n",
        "\n",
        "def deconv(inputs, shape, strides, out_num, is_sn=False):\n",
        "    filters = tf.get_variable(\"kernel\", shape=shape, initializer=tf.random_normal_initializer(stddev=0.02))\n",
        "    bias = tf.get_variable(\"bias\", shape=[shape[-2]], initializer=tf.constant_initializer([0]))\n",
        "    if is_sn:\n",
        "        return tf.nn.conv2d_transpose(inputs, spectral_norm(\"sn\", filters), out_num, strides) + bias\n",
        "    else:\n",
        "        return tf.nn.conv2d_transpose(inputs, filters, out_num, strides) + bias\n",
        "\n",
        "def conv(inputs, shape, strides, is_sn=False):\n",
        "    filters = tf.get_variable(\"kernel\", shape=shape, initializer=tf.random_normal_initializer(stddev=0.02))\n",
        "    bias = tf.get_variable(\"bias\", shape=[shape[-1]], initializer=tf.constant_initializer([0]))\n",
        "    if is_sn:\n",
        "        return tf.nn.conv2d(inputs, spectral_norm(\"sn\", filters), strides, \"SAME\") + bias\n",
        "    else:\n",
        "        return tf.nn.conv2d(inputs, filters, strides, \"SAME\") + bias\n",
        "\n",
        "def fully_connected(inputs, num_out, is_sn=False):\n",
        "    W = tf.get_variable(\"W\", [inputs.shape[-1], num_out], initializer=tf.random_normal_initializer(stddev=0.02))\n",
        "    b = tf.get_variable(\"b\", [num_out], initializer=tf.constant_initializer([0]))\n",
        "    if is_sn:\n",
        "        return tf.matmul(inputs, spectral_norm(\"sn\", W)) + b\n",
        "    else:\n",
        "        return tf.matmul(inputs, W) + b\n",
        "\n",
        "def leaky_relu(inputs, slope=0.2):\n",
        "    return tf.maximum(slope*inputs, inputs)\n",
        "\n",
        "def spectral_norm(name, w, iteration=1):\n",
        "    #Spectral normalization which was published on ICLR2018,please refer to \"https://www.researchgate.net/publication/318572189_Spectral_Normalization_for_Generative_Adversarial_Networks\"\n",
        "    #This function spectral_norm is forked from \"https://github.com/taki0112/Spectral_Normalization-Tensorflow\"\n",
        "    w_shape = w.shape.as_list()\n",
        "    w = tf.reshape(w, [-1, w_shape[-1]])\n",
        "    with tf.variable_scope(name, reuse=False):\n",
        "        u = tf.get_variable(\"u\", [1, w_shape[-1]], initializer=tf.truncated_normal_initializer(), trainable=False)\n",
        "    u_hat = u\n",
        "    v_hat = None\n",
        "\n",
        "    def l2_norm(v, eps=1e-12):\n",
        "        return v / (tf.reduce_sum(v ** 2) ** 0.5 + eps)\n",
        "\n",
        "    for i in range(iteration):\n",
        "        v_ = tf.matmul(u_hat, tf.transpose(w))\n",
        "        v_hat = l2_norm(v_)\n",
        "        u_ = tf.matmul(v_hat, w)\n",
        "        u_hat = l2_norm(u_)\n",
        "    sigma = tf.matmul(tf.matmul(v_hat, w), tf.transpose(u_hat))\n",
        "    w_norm = w / sigma\n",
        "    with tf.control_dependencies([u.assign(u_hat)]):\n",
        "        w_norm = tf.reshape(w_norm, w_shape)\n",
        "    return w_norm\n",
        "\n",
        "def mapping(x):\n",
        "    max = np.max(x)\n",
        "    min = np.min(x)\n",
        "    return (x - min) * 255.0 / (max - min + epsilon)\n",
        "\n",
        "def instanceNorm(inputs):\n",
        "    mean, var = tf.nn.moments(inputs, axes=[1, 2], keep_dims=True)\n",
        "    scale = tf.get_variable(\"scale\", shape=mean.shape, initializer=tf.constant_initializer([1.0]))\n",
        "    shift = tf.get_variable(\"shift\", shape=mean.shape, initializer=tf.constant_initializer([0.0]))\n",
        "    return (inputs - mean) * scale / (tf.sqrt(var + epsilon)) + shift\n",
        "\n",
        "class Generator:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def __call__(self, Z):\n",
        "        with tf.variable_scope(name_or_scope=self.name, reuse=False):\n",
        "            with tf.variable_scope(name_or_scope=\"linear\"):\n",
        "                inputs = tf.reshape(tf.nn.relu((fully_connected(Z, 4*4*512))), [batchsize, 4, 4, 512])\n",
        "            with tf.variable_scope(name_or_scope=\"deconv1\"):\n",
        "                inputs = tf.nn.relu(instanceNorm(deconv(inputs, [5, 5, 256, 512], [1, 2, 2, 1], [batchsize, 8, 8, 256])))\n",
        "            with tf.variable_scope(name_or_scope=\"deconv2\"):\n",
        "                inputs = tf.nn.relu(instanceNorm(deconv(inputs, [5, 5, 128, 256], [1, 2, 2, 1], [batchsize, 16, 16, 128])))\n",
        "            with tf.variable_scope(name_or_scope=\"deconv3\"):\n",
        "                inputs = tf.nn.relu(instanceNorm(deconv(inputs, [5, 5, 64, 128], [1, 2, 2, 1], [batchsize, 32, 32, 64])))\n",
        "            if img_H == 32:\n",
        "                with tf.variable_scope(name_or_scope=\"deconv4\"):\n",
        "                    inputs = tf.nn.tanh(deconv(inputs, [5, 5, img_C, 64], [1, 1, 1, 1], [batchsize, img_H, img_W, img_C]))\n",
        "                return inputs\n",
        "            with tf.variable_scope(name_or_scope=\"deconv4\"):\n",
        "                 inputs = tf.nn.tanh(deconv(inputs, [5, 5, img_C, 64], [1, 2, 2, 1], [batchsize, img_H, img_W, img_C]))\n",
        "            if img_H == 64:\n",
        "                return inputs\n",
        "\n",
        "    @property\n",
        "    def var(self):\n",
        "        return tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, self.name)\n",
        "\n",
        "class Discriminator:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def __call__(self, inputs, reuse=False, is_sn=False):\n",
        "        with tf.variable_scope(name_or_scope=self.name, reuse=reuse):\n",
        "            with tf.variable_scope(\"conv1\"):\n",
        "                inputs = leaky_relu(conv(inputs, [5, 5, img_C, 64], [1, 2, 2, 1], is_sn))\n",
        "            with tf.variable_scope(\"conv2\"):\n",
        "                inputs = leaky_relu(instanceNorm(conv(inputs, [5, 5, 64, 128], [1, 2, 2, 1], is_sn)))\n",
        "            with tf.variable_scope(\"conv3\"):\n",
        "                inputs = leaky_relu(instanceNorm(conv(inputs, [5, 5, 128, 256], [1, 2, 2, 1], is_sn)))\n",
        "            with tf.variable_scope(\"conv4\"):\n",
        "                inputs = leaky_relu(instanceNorm(conv(inputs, [5, 5, 256, 512], [1, 2, 2, 1], is_sn)))\n",
        "            inputs = tf.layers.flatten(inputs)\n",
        "            return fully_connected(inputs, 1, is_sn)\n",
        "\n",
        "    @property\n",
        "    def var(self):\n",
        "        return tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
        "\n",
        "\n",
        "class GAN:\n",
        "    #Architecture of generator and discriminator just like DCGAN.\n",
        "    def __init__(self):\n",
        "        self.Z = tf.placeholder(\"float\", [batchsize, 100])\n",
        "        self.img = tf.placeholder(\"float\", [batchsize, img_H, img_W, img_C])\n",
        "        D = Discriminator(\"discriminator\")\n",
        "        G = Generator(\"generator\")\n",
        "        self.fake_img = G(self.Z)\n",
        "        if GAN_type == \"DCGAN\":\n",
        "            #DCGAN, paper: UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS\n",
        "            self.fake_logit = tf.nn.sigmoid(D(self.fake_img))\n",
        "            self.real_logit = tf.nn.sigmoid(D(self.img, reuse=True))\n",
        "            self.d_loss = - (tf.reduce_mean(tf.log(self.real_logit + epsilon)) + tf.reduce_mean(tf.log(1 - self.fake_logit + epsilon)))\n",
        "            self.g_loss = - tf.reduce_mean(tf.log(self.fake_logit + epsilon))\n",
        "            self.opt_D = tf.train.AdamOptimizer(2e-4, beta1=0.5).minimize(self.d_loss, var_list=D.var)\n",
        "            self.opt_G = tf.train.AdamOptimizer(2e-4, beta1=0.5).minimize(self.g_loss, var_list=G.var)\n",
        "        elif GAN_type == \"WGAN\":\n",
        "            #WGAN, paper: Wasserstein GAN\n",
        "            self.fake_logit = D(self.fake_img)\n",
        "            self.real_logit = D(self.img, reuse=True)\n",
        "            self.d_loss = -tf.reduce_mean(self.real_logit) + tf.reduce_mean(self.fake_logit)\n",
        "            self.g_loss = -tf.reduce_mean(self.fake_logit)\n",
        "            self.clip = []\n",
        "            for _, var in enumerate(D.var):\n",
        "                self.clip.append(var.assign(tf.clip_by_value(var, -0.01, 0.01)))\n",
        "            self.opt_D = tf.train.RMSPropOptimizer(5e-5).minimize(self.d_loss, var_list=D.var)\n",
        "            self.opt_G = tf.train.RMSPropOptimizer(5e-5).minimize(self.g_loss, var_list=G.var)\n",
        "        elif GAN_type == \"WGAN-GP\":\n",
        "            #WGAN-GP, paper: Improved Training of Wasserstein GANs\n",
        "            self.fake_logit = D(self.fake_img)\n",
        "            self.real_logit = D(self.img, reuse=True)\n",
        "            e = tf.random_uniform([batchsize, 1, 1, 1], 0, 1)\n",
        "            x_hat = e * self.img + (1 - e) * self.fake_img\n",
        "            grad = tf.gradients(D(x_hat, reuse=True), x_hat)[0]\n",
        "            self.d_loss = tf.reduce_mean(self.fake_logit - self.real_logit) + 10 * tf.reduce_mean(tf.square(tf.sqrt(tf.reduce_sum(tf.square(grad), axis=[1, 2, 3])) - 1))\n",
        "            self.g_loss = tf.reduce_mean(-self.fake_logit)\n",
        "            self.opt_D = tf.train.AdamOptimizer(1e-4, beta1=0., beta2=0.9).minimize(self.d_loss, var_list=D.var)\n",
        "            self.opt_G = tf.train.AdamOptimizer(1e-4, beta1=0., beta2=0.9).minimize(self.g_loss, var_list=G.var)\n",
        "        elif GAN_type == \"LSGAN\":\n",
        "            #LSGAN, paper: Least Squares Generative Adversarial Networks\n",
        "            self.fake_logit = D(self.fake_img)\n",
        "            self.real_logit = D(self.img, reuse=True)\n",
        "            self.d_loss = tf.reduce_mean(0.5 * tf.square(self.real_logit - 1) + 0.5 * tf.square(self.fake_logit))\n",
        "            self.g_loss = tf.reduce_mean(0.5 * tf.square(self.fake_logit - 1))\n",
        "            self.opt_D = tf.train.AdamOptimizer(2e-4, beta1=0.5).minimize(self.d_loss, var_list=D.var)\n",
        "            self.opt_G = tf.train.AdamOptimizer(2e-4, beta1=0.5).minimize(self.g_loss, var_list=G.var)\n",
        "        elif GAN_type == \"SNGAN\":\n",
        "            #SNGAN, paper: SPECTRAL NORMALIZATION FOR GENERATIVE ADVERSARIAL NETWORKS\n",
        "            self.fake_logit = tf.nn.sigmoid(D(self.fake_img, is_sn=True))\n",
        "            self.real_logit = tf.nn.sigmoid(D(self.img, reuse=True, is_sn=True))\n",
        "            self.d_loss = - (tf.reduce_mean(tf.log(self.real_logit + epsilon) + tf.log(1 - self.fake_logit + epsilon)))\n",
        "            self.g_loss = - tf.reduce_mean(tf.log(self.fake_logit + epsilon))\n",
        "            self.opt_D = tf.train.AdamOptimizer(2e-4, beta1=0.5).minimize(self.d_loss, var_list=D.var)\n",
        "            self.opt_G = tf.train.AdamOptimizer(2e-4, beta1=0.5).minimize(self.g_loss, var_list=G.var)\n",
        "        elif GAN_type == \"RSGAN\":\n",
        "            #RSGAN, paper: The relativistic discriminator: a key element missing from standard GAN\n",
        "            self.fake_logit = D(self.fake_img)\n",
        "            self.real_logit = D(self.img, reuse=True)\n",
        "            self.d_loss = - tf.reduce_mean(tf.log(tf.nn.sigmoid(self.real_logit - self.fake_logit) + epsilon))\n",
        "            self.g_loss = - tf.reduce_mean(tf.log(tf.nn.sigmoid(self.fake_logit - self.real_logit) + epsilon))\n",
        "            self.opt_D = tf.train.AdamOptimizer(2e-4, beta1=0.5).minimize(self.d_loss, var_list=D.var)\n",
        "            self.opt_G = tf.train.AdamOptimizer(2e-4, beta1=0.5).minimize(self.g_loss, var_list=G.var)\n",
        "        elif GAN_type == \"RaSGAN\":\n",
        "            #RaSGAN, paper: The relativistic discriminator: a key element missing from standard GAN\n",
        "            self.fake_logit = D(self.fake_img)\n",
        "            self.real_logit = D(self.img, reuse=True)\n",
        "            self.avg_fake_logit = tf.reduce_mean(self.fake_logit)\n",
        "            self.avg_real_logit = tf.reduce_mean(self.real_logit)\n",
        "            self.D_r_tilde = tf.nn.sigmoid(self.real_logit - self.avg_fake_logit)\n",
        "            self.D_f_tilde = tf.nn.sigmoid(self.fake_logit - self.avg_real_logit)\n",
        "            self.d_loss = - tf.reduce_mean(tf.log(self.D_r_tilde + epsilon)) - tf.reduce_mean(tf.log(1 - self.D_f_tilde + epsilon))\n",
        "            self.g_loss = - tf.reduce_mean(tf.log(self.D_f_tilde + epsilon)) - tf.reduce_mean(tf.log(1 - self.D_r_tilde + epsilon))\n",
        "            self.opt_D = tf.train.AdamOptimizer(2e-4, beta1=0.5).minimize(self.d_loss, var_list=D.var)\n",
        "            self.opt_G = tf.train.AdamOptimizer(2e-4, beta1=0.5).minimize(self.g_loss, var_list=G.var)\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    def __call__(self):\n",
        "        saver = tf.train.Saver()\n",
        "        epoch_nums = 200\n",
        "        facedata = sio.loadmat(\"./facedata.mat\")[\"data\"]\n",
        "        #For face data, i random select about 10,000 images from CelebA and resize them to 64x64 by Matlab.\n",
        "        for epoch in range(epoch_nums):\n",
        "            for i in range(facedata.__len__()//batchsize-1):\n",
        "                batch = facedata[i*batchsize:i*batchsize+batchsize, :, :, :] / 255.0\n",
        "                z = np.random.standard_normal([batchsize, 100])\n",
        "                d_loss = self.sess.run(self.d_loss, feed_dict={self.img: batch, self.Z: z})\n",
        "                g_loss = self.sess.run(self.g_loss, feed_dict={self.img: batch, self.Z: z})\n",
        "                self.sess.run(self.opt_D, feed_dict={self.img: batch, self.Z: z})\n",
        "                if GAN_type == \"WGAN\":\n",
        "                    self.sess.run(self.clip)#WGAN weight clipping\n",
        "                self.sess.run(self.opt_G, feed_dict={self.img: batch, self.Z: z})\n",
        "                if i % 100 == 0:\n",
        "                    print(\"epoch: %d, step: %d, d_loss: %g, g_loss: %g\"%(epoch, i,  d_loss, g_loss))\n",
        "                    z = np.random.standard_normal([batchsize, 100])\n",
        "                    imgs = self.sess.run(self.fake_img, feed_dict={self.img: batch, self.Z: z})\n",
        "                    for j in range(batchsize):\n",
        "                        if img_C == 1:\n",
        "                            Image.fromarray(np.reshape(np.uint8(mapping(imgs[j, :, :, :])), [img_H, img_W])).save(\n",
        "                                \"./result//\" + str(epoch) + \"_\" + str(j) + \".jpg\")\n",
        "                        else:\n",
        "                            Image.fromarray(np.uint8(mapping(imgs[j, :, :, :]))).save(\n",
        "                                \"./result//\" + str(epoch) + \"_\" + str(j) + \".jpg\")\n",
        "            if epoch % 10 == 0:\n",
        "                 saver.save(self.sess, \"./para//model.ckpt\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gan = GAN()\n",
        "    gan()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-3-991d44cc883a>:117: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "epoch: 0, step: 0, d_loss: 1.50482, g_loss: 0.782245\n",
            "epoch: 0, step: 100, d_loss: 0.459042, g_loss: 1.47288\n",
            "epoch: 1, step: 0, d_loss: 0.885583, g_loss: 1.09523\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}